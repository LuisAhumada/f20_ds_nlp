{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will be analyzing a number of articles. One odd property is that some of these documents have copies of material lifted from other documents. Thus, you can assume there is some amount of plagiarism in these documents. Your task is to develop a set of scripts to examine all the files and attempting to identify which documents share sentences. \n",
    "\n",
    "Here it is important to stress that there are two properties of this borrowing that should make your task simpler. The first is that you only need to look for whole sentence borrowing. The second property is that the borrowings will either be exact sentence duplication or will have a new word added to the sentence with the remainder of the sentence being the same. Documents can have more than one borrowed sentence in it.\n",
    "\n",
    "An approach that you might take is to have a set of loops to compare each document to each other document (here realize you only need to compare a document to another once, that is you don't have to compare them from either side). Once you are comparing two documents you will want to segment the text into setences and then either compare the sentences of each document for exact matches, or compare the sentences with some notion of a distance metric. \n",
    "\n",
    "You will need to return a list of documents that have borrowed material and then identify the links, e.g. doc 1 contains a sentence from doc 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = \"/homeworks/homework_1/data/\" # point this to the data directory\n",
    "\n",
    "# you can use the below code to read all of the text files and then have them available in a list\n",
    "\n",
    "def read_file(filename):\n",
    "    input_file_text = open(filename , encoding='utf-8').read()\n",
    "    return input_file_text\n",
    "\n",
    "    \n",
    "def read_directory_files(directory):\n",
    "    file_texts = []\n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    for f in files:\n",
    "        file_text = read_file(join(directory, f))\n",
    "        print(file_text)\n",
    "        file_texts.append({\"file\":f, \"content\": file_text })\n",
    "    return file_texts\n",
    "    \n",
    "# here we will generate the list that contains all the files and their contents\n",
    "text_corpus = read_directory_files(dir_base)\n",
    "print(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_sentences(doc_1, doc_2):\n",
    "    for sentence in doc_1.sents:\n",
    "        # compare these sentences to sentences in doc 2\n",
    "        \n",
    "        # compare an exact sentence match here\n",
    "        \n",
    "        # also, try to look at the tokens in the sentences and see if they overlap much.\n",
    "        # You could take the list of tokens and then get the set difference and see if it is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will be iterating \n",
    "for left_doc in text_corpus.keys():\n",
    "    for right_doc in text_corpus.keys():\n",
    "        # you will need to look at the content of each document\n",
    "        # obviously you will want to tokenize the documents with spacy here\n",
    "        \n",
    "        find_overlapping_sentences(analyzed doc 1, analyzed doc 2)\n",
    "        \n",
    "        # mark the document as containing overlap here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put a brief report of your approach, your results, and any conclusions you can draw from this here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit: \n",
    "\n",
    "Print out the exact sentence match and identify the sentences that are a match with an extra word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
